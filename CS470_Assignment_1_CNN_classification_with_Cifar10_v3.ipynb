{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS470 Assignment #1: CNN classification with Cifar10_v3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stmoon/CS470/blob/master/CS470_Assignment_1_CNN_classification_with_Cifar10_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqPMAzzNipD",
        "colab_type": "text"
      },
      "source": [
        "CS470 Assignment #1: CNN classification with Cifar10\n",
        "====\n",
        "\n",
        "Primary TA : Myeongjae Jang\n",
        "\n",
        "TA's E-mail : myeongjae0409@kaist.ac.kr\n",
        "\n",
        "## Instruction\n",
        "\n",
        "- Modify the baseline CNN model to improve the classification performance on Cifar10 dataset. In addition to the model definition, you can modify any parts of this colab example to improve the test accuracy (e.g., learning rate, batch size, etc.)\n",
        "- Train your CNN model and compare it to the baseline (in terms of training loss and the test accuracy).\n",
        "- Explain your modifications and discuss how you improved the test accuracy.\n",
        "\n",
        "## Submission guidelines\n",
        "\n",
        "- Your code and report will be all in Colab. Copy this example to your google drive and edit it to complete your assignment. Add sections at the bottom of this example to discuss the results. For discussion and analysis, we highly encourage you to use graphics if possible (e.g., plots, images, etc.). \n",
        "- To make grading efficient, please highlight all contributions & modifications you made clearly. We highly encourage you to add code blocks in the discussion section to discuss your modifications (e.g., you can describe the model definition in the discussion section using the code blocks).\n",
        "- We should be able to reproduce your results using your code and pre-trained model. Please double-check if your code runs without error and loads your pre-trained model properly. Submissions failed to run or reproduce the results will get a substantial penalty. \n",
        "- In this assignment, **we are not allowing fine-tuning from the pre-trained model** (e.g. ImageNet pre-trained models). You should train your  model on Cifar10 dataset from scratch. \n",
        "\n",
        "## Deliverables\n",
        "- Download your Colab notebook and the pre-trained model, and submit a zip file in a format: [StudentID].zip. Please double-check that you locate and load your pre-trained model properly.\n",
        "- Your assignment should be submitted through KLMS. All other submissions (e.g., via email) will not be considered as valid submissions. \n",
        "\n",
        "## Grading policy\n",
        "\n",
        "- **Code** (50%): Your code should work and outperform the baseline model in terms of the test accuracy. \n",
        "- **Report** (50%): Explain your modification and justify how it improved the perofrmance. It would be great if you have some supporting results for your justification (e.g., justifying that you resolved the overfitting by comparing two training/testing loss curves). \n",
        "- **Extra points** will be given if your submission satisfies the following:\n",
        " - **High test accuracy**: we will rank the submissions based on the test accuracy, and assign extra points according to the rank (e.g. 3 points for top 10%, 2 points for top 30%, 1 points for top 50%.)\n",
        " - **Comprehensive discussion**: we will assign extra points if your report contains comprehensive discussion/analysis of the results. Examples include justification of your choice of model (or hyper-parameters), comparisons to the baseline model (analysis on the source of improvement), insightful visualizations (loss curves, misclassification results), etc.\n",
        "\n",
        "## Due date\n",
        "- **23:59:59 September 25th.**\n",
        "- Late submission is allowed until 23:59:59 September 27th.\n",
        "- Late submission will be applied 20% penalty.\n",
        "\n",
        "## Questions\n",
        "- Please use QnA board in KLMS as a main communication channel. When you post questions, please make it public so that all students can share the information. Please use the prefix \"[Assignment 1]\" in the subject for all questions regarding this assignment (e.g., [Assignment 1] Regarding the grading policy).\n",
        "\n",
        "## PyTorch Documentation\n",
        "- You can refer PyTorch documentation for your assignment.\n",
        "- https://pytorch.org/docs/stable/index.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1mgGV_uOIK",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Connect to your Google Drive\n",
        "\n",
        "It is required if you want to save checkpoints and load them later on.\n",
        "\n",
        "### (You have to submit your trained results as the checkpoint. So, please check your Google Drive connection again.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLth6ZfXuSGT",
        "colab_type": "code",
        "outputId": "fd94ae0d-e3eb-429b-b109-ad3ffde35a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYwUwGf8qW1U",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UtshANjqpy4",
        "colab_type": "code",
        "outputId": "98a4f524-19ef-4f25-820a-f2154922b21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install -U tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iJ-Q6sbq8c3",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Configure the experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA5jAy7Wq-E2",
        "colab_type": "code",
        "outputId": "3ac5690f-3bbd-41f0-93d6-5575e526c9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# training & optimization hyper-parameters\n",
        "max_epoch = 200\n",
        "learning_rate = 0.001\n",
        "batch_size = 20000\n",
        "device = 'cuda'\n",
        "\n",
        "# model hyper-parameters\n",
        "output_dim = 10 \n",
        "\n",
        "# Boolean value to select training process\n",
        "training_process = True\n",
        "\n",
        "# initialize tensorboard for visualization\n",
        "# Note : click the Tensorboard link to see the visualization of training/testing results\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://4a55be78.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tZt60aMrQ1g",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Construct data pipeline\n",
        "\n",
        "**`torchvision.datasets.CIFAR10`** will automatically construct **`Cifar10`** dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHbtV46LrXOF",
        "colab_type": "code",
        "outputId": "55bb6336-c58d-4410-a010-fd955f0cda9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "data_dir = os.path.join(gdrive_root, 'my_data')\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc3cxhEX8r7b",
        "colab_type": "code",
        "outputId": "22281ad7-07bf-46cd-bb04-28bfc0bed718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['image.interpolation'] = 'nearest'\n",
        "mpl.rcParams['figure.figsize'] = 10, 15\n",
        "\n",
        "def show_dataset(dataset, n=6):\n",
        "  img = np.vstack((np.hstack((np.asarray(dataset[i][0]) for _ in range(n)))\n",
        "                   for i in range(10)))\n",
        "  print(img.shape)\n",
        "  plt.imshow(img[3,:,:])\n",
        "  plt.axis('off')\n",
        "  \n",
        "  \n",
        "show_dataset(train_dataset)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4567eb27b9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mshow_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G_dWd-6rwWb",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Construct a neural network builder\n",
        "\n",
        "We serve the baseline CNN model which is supported on Pytorch tutorial: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb#scrollTo=c1E1b7-igUcR\n",
        "\n",
        "### (You have to compare your own CNN model's test accuracy with the baseline CNN model and explain why your own model's test accuracy is higher than the basline.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX_wne0Vr1E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(MyClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(num_features=6)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(num_features=32)\n",
        "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1)\n",
        "        self.fc1 = nn.Linear(in_features=64 * 1 * 1, out_features=64)\n",
        "        self.fc2 = nn.Linear(in_features=64, out_features=output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.pool(self.relu(self.batchnorm1(self.conv1(x))))\n",
        "      x = self.pool(self.relu(self.conv2(x)))\n",
        "      x = self.pool(self.relu(self.batchnorm3(self.conv3(x))))\n",
        "      x = self.pool(self.relu(self.conv4(x)))\n",
        "      x = x.view(-1, 64 * 1 * 1)\n",
        "      x = self.relu(self.fc1(x))\n",
        "      outputs = self.fc2(x)\n",
        "      return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpA3xhjMspvA",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Initialize the network and optimizer\n",
        "\n",
        "If you want to train modularized neural network in Step 5B, please use 'MyClassifier2' as 'my_classifier'. It is written as a comment now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP111gW0s8aH",
        "colab_type": "code",
        "outputId": "fc298bac-73cc-4fb1-f57f-6c3f9f2b9838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "my_classifier = MyClassifier()\n",
        "my_classifier = my_classifier.to(device)\n",
        "\n",
        "# Print your neural network structure\n",
        "print(my_classifier)\n",
        "\n",
        "optimizer = optim.Adam(my_classifier.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyClassifier(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (batchnorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (batchnorm3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lAQeXmjsILS",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Load pre-trained weights if exist\n",
        "\n",
        "- **For your sumbmission you have to store the trained model as a checkpoint.**\n",
        "- Please do not erase this step.\n",
        "- If you want to modify this step, please be careful.\n",
        "- After training please confirm that your checkpoint is correctly stored and re-loaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFLNZxaBsHUl",
        "colab_type": "code",
        "outputId": "14e0810c-fe61-430f-f6c9-6f8d2bc651d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  os.makedirs(ckpt_dir)\n",
        "  \n",
        "best_acc = 0.\n",
        "ckpt_path = os.path.join(ckpt_dir, 'lastest.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "  ckpt = torch.load(ckpt_path)\n",
        "  try:\n",
        "    my_classifier.load_state_dict(ckpt['my_classifier'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer'])\n",
        "    best_acc = ckpt['best_acc']\n",
        "  except RuntimeError as e:\n",
        "      print('wrong checkpoint')\n",
        "  else:    \n",
        "    print('checkpoint is loaded !')\n",
        "    print('current best accuracy : %.2f' % best_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint is loaded !\n",
            "current best accuracy : 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1t7n6yttNEc",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Train the network\n",
        "\n",
        "Note : It would be better to save checkpoints periodically, otherwise you'll lose everything you've trained if the session is recycled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vczdKbytV38",
        "colab_type": "code",
        "outputId": "2cf7a957-05ba-432d-ab41-e9e8e4f0aa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if training_process:\n",
        "  it = 0\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  for epoch in range(max_epoch):\n",
        "    # train phase\n",
        "    my_classifier.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "      it += 1\n",
        "\n",
        "      # load data to the GPU.\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # feed data into the network and get outputs.\n",
        "      logits = my_classifier(inputs)\n",
        "\n",
        "      # calculate loss\n",
        "      # Note: `F.cross_entropy` function receives logits, or pre-softmax outputs, rather than final probability scores.\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "      # Note: You should flush out gradients computed at the previous step before computing gradients at the current step. \n",
        "      #       Otherwise, gradients will accumulate.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # backprogate loss.\n",
        "      loss.backward()\n",
        "\n",
        "      # update the weights in the network.\n",
        "      optimizer.step()\n",
        "\n",
        "      # calculate accuracy.\n",
        "      acc = (logits.argmax(dim=1) == labels).float().mean()\n",
        "\n",
        "      if it % 2000 == 0:\n",
        "        tbc.save_value('Loss', 'train_loss', it, loss.item())\n",
        "        print('[epoch:{}, iteration:{}] train loss : {:.4f} train accuracy : {:.4f}'.format(epoch, it, loss.item(), acc.item()))\n",
        "\n",
        "    # save losses in a list so that we can visualize them later.\n",
        "    train_losses.append(loss)  \n",
        "\n",
        "    # test phase\n",
        "    n = 0.\n",
        "    test_loss = 0.\n",
        "    test_acc = 0.\n",
        "    my_classifier.eval()\n",
        "    for test_inputs, test_labels in test_dataloader:\n",
        "      test_inputs = test_inputs.to(device)\n",
        "      test_labels = test_labels.to(device)\n",
        "\n",
        "      logits = my_classifier(test_inputs)\n",
        "      test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item()\n",
        "      test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item()\n",
        "      n += test_inputs.size(0)\n",
        "\n",
        "    test_loss /= n\n",
        "    test_acc /= n\n",
        "    test_losses.append(test_loss)\n",
        "    tbc.save_value('Loss', 'test_loss', it, test_loss)\n",
        "    print('[epoch:{}, iteration:{}] test_loss : {:.4f} test accuracy : {:.4f}'.format(epoch, it, test_loss, test_acc)) \n",
        "\n",
        "    tbc.flush_line('train_loss')\n",
        "    tbc.flush_line('test_loss')\n",
        "\n",
        "    # save checkpoint whenever there is improvement in performance\n",
        "    if test_acc > best_acc:\n",
        "      best_acc = test_acc\n",
        "      # Note: optimizer also has states ! don't forget to save them as well.\n",
        "      ckpt = {'my_classifier':my_classifier.state_dict(),\n",
        "              'optimizer':optimizer.state_dict(),\n",
        "              'best_acc':best_acc}\n",
        "      torch.save(ckpt, ckpt_path)\n",
        "      print('checkpoint is saved !')\n",
        "    \n",
        "tbc.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch:0, iteration:2000] train loss : 0.1004 train accuracy : 1.0000\n",
            "[epoch:0, iteration:4000] train loss : 1.1606 train accuracy : 0.5000\n",
            "[epoch:0, iteration:6000] train loss : 1.2641 train accuracy : 0.5000\n",
            "[epoch:0, iteration:8000] train loss : 1.6242 train accuracy : 0.5000\n",
            "[epoch:0, iteration:10000] train loss : 1.1130 train accuracy : 0.5000\n",
            "[epoch:0, iteration:12000] train loss : 1.0600 train accuracy : 0.2500\n",
            "[epoch:0, iteration:12500] test_loss : 0.9948 test accuracy : 0.6578\n",
            "[epoch:1, iteration:14000] train loss : 1.0463 train accuracy : 0.5000\n",
            "[epoch:1, iteration:16000] train loss : 1.2332 train accuracy : 0.5000\n",
            "[epoch:1, iteration:18000] train loss : 0.5408 train accuracy : 0.7500\n",
            "[epoch:1, iteration:20000] train loss : 0.2126 train accuracy : 1.0000\n",
            "[epoch:1, iteration:22000] train loss : 1.9852 train accuracy : 0.5000\n",
            "[epoch:1, iteration:24000] train loss : 1.2167 train accuracy : 0.5000\n",
            "[epoch:1, iteration:25000] test_loss : 0.9917 test accuracy : 0.6631\n",
            "[epoch:2, iteration:26000] train loss : 1.4393 train accuracy : 0.5000\n",
            "[epoch:2, iteration:28000] train loss : 1.1067 train accuracy : 0.5000\n",
            "[epoch:2, iteration:30000] train loss : 1.0827 train accuracy : 0.5000\n",
            "[epoch:2, iteration:32000] train loss : 1.1942 train accuracy : 0.7500\n",
            "[epoch:2, iteration:34000] train loss : 1.1177 train accuracy : 0.7500\n",
            "[epoch:2, iteration:36000] train loss : 1.1210 train accuracy : 0.7500\n",
            "[epoch:2, iteration:37500] test_loss : 0.9826 test accuracy : 0.6653\n",
            "[epoch:3, iteration:38000] train loss : 0.9043 train accuracy : 0.5000\n",
            "[epoch:3, iteration:40000] train loss : 0.3280 train accuracy : 0.7500\n",
            "[epoch:3, iteration:42000] train loss : 0.8390 train accuracy : 0.7500\n",
            "[epoch:3, iteration:44000] train loss : 0.2081 train accuracy : 1.0000\n",
            "[epoch:3, iteration:46000] train loss : 1.5866 train accuracy : 0.5000\n",
            "[epoch:3, iteration:48000] train loss : 0.5890 train accuracy : 0.7500\n",
            "[epoch:3, iteration:50000] train loss : 0.7983 train accuracy : 0.7500\n",
            "[epoch:3, iteration:50000] test_loss : 0.9813 test accuracy : 0.6655\n",
            "[epoch:4, iteration:52000] train loss : 1.6259 train accuracy : 0.5000\n",
            "[epoch:4, iteration:54000] train loss : 1.1538 train accuracy : 0.5000\n",
            "[epoch:4, iteration:56000] train loss : 0.4573 train accuracy : 1.0000\n",
            "[epoch:4, iteration:58000] train loss : 1.3397 train accuracy : 0.5000\n",
            "[epoch:4, iteration:60000] train loss : 1.3089 train accuracy : 0.5000\n",
            "[epoch:4, iteration:62000] train loss : 0.8788 train accuracy : 0.5000\n",
            "[epoch:4, iteration:62500] test_loss : 0.9896 test accuracy : 0.6603\n",
            "[epoch:5, iteration:64000] train loss : 1.4456 train accuracy : 0.5000\n",
            "[epoch:5, iteration:66000] train loss : 0.5389 train accuracy : 1.0000\n",
            "[epoch:5, iteration:68000] train loss : 0.1701 train accuracy : 1.0000\n",
            "[epoch:5, iteration:70000] train loss : 1.4266 train accuracy : 0.5000\n",
            "[epoch:5, iteration:72000] train loss : 0.7799 train accuracy : 0.7500\n",
            "[epoch:5, iteration:74000] train loss : 0.6364 train accuracy : 0.7500\n",
            "[epoch:5, iteration:75000] test_loss : 0.9975 test accuracy : 0.6558\n",
            "[epoch:6, iteration:76000] train loss : 1.4651 train accuracy : 0.2500\n",
            "[epoch:6, iteration:78000] train loss : 0.3621 train accuracy : 0.7500\n",
            "[epoch:6, iteration:80000] train loss : 0.6017 train accuracy : 0.7500\n",
            "[epoch:6, iteration:82000] train loss : 1.8519 train accuracy : 0.5000\n",
            "[epoch:6, iteration:84000] train loss : 0.3574 train accuracy : 1.0000\n",
            "[epoch:6, iteration:86000] train loss : 0.7267 train accuracy : 0.7500\n",
            "[epoch:6, iteration:87500] test_loss : 0.9840 test accuracy : 0.6642\n",
            "[epoch:7, iteration:88000] train loss : 0.7388 train accuracy : 0.7500\n",
            "[epoch:7, iteration:90000] train loss : 0.5767 train accuracy : 0.7500\n",
            "[epoch:7, iteration:92000] train loss : 0.2858 train accuracy : 1.0000\n",
            "[epoch:7, iteration:94000] train loss : 1.2443 train accuracy : 0.7500\n",
            "[epoch:7, iteration:96000] train loss : 0.6627 train accuracy : 0.7500\n",
            "[epoch:7, iteration:98000] train loss : 1.4312 train accuracy : 0.5000\n",
            "[epoch:7, iteration:100000] train loss : 0.4659 train accuracy : 0.7500\n",
            "[epoch:7, iteration:100000] test_loss : 0.9907 test accuracy : 0.6597\n",
            "[epoch:8, iteration:102000] train loss : 1.9134 train accuracy : 0.2500\n",
            "[epoch:8, iteration:104000] train loss : 2.5026 train accuracy : 0.2500\n",
            "[epoch:8, iteration:106000] train loss : 0.8693 train accuracy : 0.5000\n",
            "[epoch:8, iteration:108000] train loss : 0.2811 train accuracy : 1.0000\n",
            "[epoch:8, iteration:110000] train loss : 0.9859 train accuracy : 0.5000\n",
            "[epoch:8, iteration:112000] train loss : 1.3020 train accuracy : 0.7500\n",
            "[epoch:8, iteration:112500] test_loss : 0.9878 test accuracy : 0.6627\n",
            "[epoch:9, iteration:114000] train loss : 0.8811 train accuracy : 0.5000\n",
            "[epoch:9, iteration:116000] train loss : 1.0094 train accuracy : 0.5000\n",
            "[epoch:9, iteration:118000] train loss : 0.2048 train accuracy : 1.0000\n",
            "[epoch:9, iteration:120000] train loss : 1.3786 train accuracy : 0.5000\n",
            "[epoch:9, iteration:122000] train loss : 0.3191 train accuracy : 1.0000\n",
            "[epoch:9, iteration:124000] train loss : 0.3640 train accuracy : 1.0000\n",
            "[epoch:9, iteration:125000] test_loss : 0.9713 test accuracy : 0.6678\n",
            "[epoch:10, iteration:126000] train loss : 0.4376 train accuracy : 0.7500\n",
            "[epoch:10, iteration:128000] train loss : 0.7615 train accuracy : 0.5000\n",
            "[epoch:10, iteration:130000] train loss : 0.5730 train accuracy : 0.7500\n",
            "[epoch:10, iteration:132000] train loss : 0.9872 train accuracy : 0.7500\n",
            "[epoch:10, iteration:134000] train loss : 0.6329 train accuracy : 0.7500\n",
            "[epoch:10, iteration:136000] train loss : 1.8620 train accuracy : 0.2500\n",
            "[epoch:10, iteration:137500] test_loss : 0.9872 test accuracy : 0.6647\n",
            "[epoch:11, iteration:138000] train loss : 0.6421 train accuracy : 0.7500\n",
            "[epoch:11, iteration:140000] train loss : 2.2619 train accuracy : 0.5000\n",
            "[epoch:11, iteration:142000] train loss : 0.5487 train accuracy : 1.0000\n",
            "[epoch:11, iteration:144000] train loss : 0.6524 train accuracy : 0.7500\n",
            "[epoch:11, iteration:146000] train loss : 2.2346 train accuracy : 0.2500\n",
            "[epoch:11, iteration:148000] train loss : 0.7689 train accuracy : 0.7500\n",
            "[epoch:11, iteration:150000] train loss : 1.9282 train accuracy : 0.2500\n",
            "[epoch:11, iteration:150000] test_loss : 1.0040 test accuracy : 0.6541\n",
            "[epoch:12, iteration:152000] train loss : 1.4173 train accuracy : 0.5000\n",
            "[epoch:12, iteration:154000] train loss : 0.8984 train accuracy : 0.7500\n",
            "[epoch:12, iteration:156000] train loss : 0.3825 train accuracy : 1.0000\n",
            "[epoch:12, iteration:158000] train loss : 0.7546 train accuracy : 0.7500\n",
            "[epoch:12, iteration:160000] train loss : 1.2939 train accuracy : 0.5000\n",
            "[epoch:12, iteration:162000] train loss : 0.5863 train accuracy : 0.7500\n",
            "[epoch:12, iteration:162500] test_loss : 1.0008 test accuracy : 0.6599\n",
            "[epoch:13, iteration:164000] train loss : 1.8995 train accuracy : 0.5000\n",
            "[epoch:13, iteration:166000] train loss : 2.1784 train accuracy : 0.5000\n",
            "[epoch:13, iteration:168000] train loss : 1.8715 train accuracy : 0.2500\n",
            "[epoch:13, iteration:170000] train loss : 1.3796 train accuracy : 0.2500\n",
            "[epoch:13, iteration:172000] train loss : 1.7578 train accuracy : 0.2500\n",
            "[epoch:13, iteration:174000] train loss : 0.5522 train accuracy : 1.0000\n",
            "[epoch:13, iteration:175000] test_loss : 0.9829 test accuracy : 0.6610\n",
            "[epoch:14, iteration:176000] train loss : 0.8193 train accuracy : 0.7500\n",
            "[epoch:14, iteration:178000] train loss : 0.8443 train accuracy : 0.5000\n",
            "[epoch:14, iteration:180000] train loss : 0.6675 train accuracy : 0.7500\n",
            "[epoch:14, iteration:182000] train loss : 0.5456 train accuracy : 0.7500\n",
            "[epoch:14, iteration:184000] train loss : 0.8727 train accuracy : 0.7500\n",
            "[epoch:14, iteration:186000] train loss : 0.8362 train accuracy : 0.7500\n",
            "[epoch:14, iteration:187500] test_loss : 0.9829 test accuracy : 0.6649\n",
            "[epoch:15, iteration:188000] train loss : 0.9450 train accuracy : 0.7500\n",
            "[epoch:15, iteration:190000] train loss : 0.6293 train accuracy : 0.7500\n",
            "[epoch:15, iteration:192000] train loss : 0.2265 train accuracy : 1.0000\n",
            "[epoch:15, iteration:194000] train loss : 0.5888 train accuracy : 0.7500\n",
            "[epoch:15, iteration:196000] train loss : 1.1693 train accuracy : 0.7500\n",
            "[epoch:15, iteration:198000] train loss : 0.4462 train accuracy : 1.0000\n",
            "[epoch:15, iteration:200000] train loss : 1.1171 train accuracy : 0.7500\n",
            "[epoch:15, iteration:200000] test_loss : 0.9977 test accuracy : 0.6641\n",
            "[epoch:16, iteration:202000] train loss : 1.9800 train accuracy : 0.2500\n",
            "[epoch:16, iteration:204000] train loss : 0.1149 train accuracy : 1.0000\n",
            "[epoch:16, iteration:206000] train loss : 1.3396 train accuracy : 0.5000\n",
            "[epoch:16, iteration:208000] train loss : 1.5723 train accuracy : 0.2500\n",
            "[epoch:16, iteration:210000] train loss : 0.7460 train accuracy : 0.7500\n",
            "[epoch:16, iteration:212000] train loss : 1.7293 train accuracy : 0.5000\n",
            "[epoch:16, iteration:212500] test_loss : 0.9941 test accuracy : 0.6601\n",
            "[epoch:17, iteration:214000] train loss : 0.6104 train accuracy : 0.7500\n",
            "[epoch:17, iteration:216000] train loss : 1.0305 train accuracy : 0.5000\n",
            "[epoch:17, iteration:218000] train loss : 0.6431 train accuracy : 0.7500\n",
            "[epoch:17, iteration:220000] train loss : 0.4545 train accuracy : 1.0000\n",
            "[epoch:17, iteration:222000] train loss : 0.9430 train accuracy : 0.7500\n",
            "[epoch:17, iteration:224000] train loss : 1.5006 train accuracy : 0.5000\n",
            "[epoch:17, iteration:225000] test_loss : 0.9796 test accuracy : 0.6671\n",
            "[epoch:18, iteration:226000] train loss : 1.6650 train accuracy : 0.7500\n",
            "[epoch:18, iteration:228000] train loss : 1.3841 train accuracy : 0.5000\n",
            "[epoch:18, iteration:230000] train loss : 0.0835 train accuracy : 1.0000\n",
            "[epoch:18, iteration:232000] train loss : 1.0150 train accuracy : 0.7500\n",
            "[epoch:18, iteration:234000] train loss : 1.3278 train accuracy : 0.5000\n",
            "[epoch:18, iteration:236000] train loss : 0.7936 train accuracy : 0.5000\n",
            "[epoch:18, iteration:237500] test_loss : 0.9782 test accuracy : 0.6650\n",
            "[epoch:19, iteration:238000] train loss : 0.7096 train accuracy : 0.5000\n",
            "[epoch:19, iteration:240000] train loss : 0.7990 train accuracy : 0.7500\n",
            "[epoch:19, iteration:242000] train loss : 0.7017 train accuracy : 0.7500\n",
            "[epoch:19, iteration:244000] train loss : 0.1822 train accuracy : 1.0000\n",
            "[epoch:19, iteration:246000] train loss : 0.6962 train accuracy : 0.7500\n",
            "[epoch:19, iteration:248000] train loss : 1.0396 train accuracy : 0.7500\n",
            "[epoch:19, iteration:250000] train loss : 0.1525 train accuracy : 1.0000\n",
            "[epoch:19, iteration:250000] test_loss : 0.9756 test accuracy : 0.6632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECu3yS0OvfoR",
        "colab_type": "text"
      },
      "source": [
        "## Step 9: Visualize and analyze the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G89sqVp-vLRy",
        "colab_type": "code",
        "outputId": "9713126a-e0a4-443d-a136-389a433e0400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "\n",
        "if not training_process:\n",
        "  # Re-load trained model\n",
        "  my_classifier.load_state_dict(ckpt['my_classifier'])\n",
        "  optimizer.load_state_dict(ckpt['optimizer'])\n",
        "\n",
        "  # Testing\n",
        "  n = 0.\n",
        "  test_loss = 0.\n",
        "  test_acc = 0.\n",
        "  my_classifier.eval()\n",
        "  for test_inputs, test_labels in test_dataloader:\n",
        "    test_inputs = test_inputs.to(device)\n",
        "    test_labels = test_labels.to(device)\n",
        "\n",
        "    logits = my_classifier(test_inputs)\n",
        "    test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item()\n",
        "    test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item()\n",
        "    n += test_inputs.size(0)\n",
        "\n",
        "  test_loss /= n\n",
        "  test_acc /= n\n",
        "  print('Test_loss : {:.4f}, Test accuracy : {:.4f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test_loss : 0.9796, Test accuracy : 0.6688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZCDk3AmCIDIQcu4EQRAZyP8PHdABKywNx4wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHjD9SGrvhzc",
        "colab_type": "code",
        "outputId": "212d9c34-61b7-4806-81da-69c863211321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "my_classifier.eval()\n",
        "\n",
        "num_test_samples = len(test_dataset)\n",
        "random_idx = random.randint(0, num_test_samples)\n",
        "\n",
        "test_input, test_label = test_dataset.__getitem__(random_idx)\n",
        "test_prediction = F.softmax(my_classifier(test_input.unsqueeze(0).to(device)), dim=1).argmax().item()\n",
        "print('label : %s' % classes[test_label])\n",
        "print('prediction : %s' % classes[test_prediction])\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(test_input))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label : deer\n",
            "prediction : deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHpJJREFUeJztnVuMXNd1pv9V59S1r+wLyeZFIiXT\nSjT2mFI6ijMWAucKxQhGNmIY9oOhByMMghgYA5kHwQOMPcA8OEFsww8DD+iREGXg8WV8GQuJc5E1\nmWgcOJIpW6IkU7YkihTZat6bzb7XbeWhigOqvf/dTTa7Wpr9fwDB6rNqn7POrrPqVO2/1lrm7hBC\npEdhqx0QQmwNCn4hEkXBL0SiKPiFSBQFvxCJouAXIlEU/EIkioJfiERR8AuRKPlGBpvZfQC+ACAD\n8N/c/TOx55cqVa/2D5B93cjx+XuXIbbDyK8ajdvojyFjzkcOVYiMc2/zgZHD0TmJ/JIz9iNPi/nI\nh8GINTZVsVesUOCvdbsdm6vwuFa7dUP7a0cmK3bNxa5VPobvj83HwuxlLC8triuabjj4zSwD8F8A\n/DaA0wB+aGaPuvtP2Jhq/wDe828/GHYky67bh6xcprai8VMrtJvU1s74C98gr3tmEd+bfH/VEve/\nXl+mtnbOL9xKuRbc3qrzMa069zEvV7gfkQAq5uF9FjMePHkkPsqRuVpcrlNboVgKbp9bXKBj5pcW\nqW1luUFteVaktlKpSm3wcKzmOb+GK5XwfPzNlx/ix1nFRj723wPgZXc/7u51AF8FcP8G9ieE6CEb\nCf7dAE5d8/fp7jYhxFuATV/wM7NDZnbEzI7Ul5c2+3BCiHWykeCfArD3mr/3dLe9AXc/7O6T7j5Z\nqkS+9wghespGgv+HAA6Y2X4zKwH4MIBHb45bQojN5oZX+929aWYfB/B36Eh9D7v7C7ExZlyiaLX4\nyjEbU4ysssekMo8sKxdzvs9CK7zPQmwai3x1Oyvycd7kPuYZH8fkoWKRn1cptr8CH5dFFJXBWniV\nveB8tdxX+Ar8aB//1Dgbea1bRLbLi3xlvpaH5WgAaPZRE+oRZafe5Nd3RubYENnfSvgrtMdkz1Vs\nSOd39+8C+O5G9iGE2Br0Cz8hEkXBL0SiKPiFSBQFvxCJouAXIlE2tNp//RhN4PFI1hbtLUCkNwBo\nR3LOlls8EaRmXAJykhyTR+TBVkSGqje57HX+0kVqGxocpLZmI5y0lEXmoxyRvXx5hdqWFrg0t//t\ntwW3jw0M8WOtcDlvcIBrbOcj52Z5+NwuzUd+bVoLJ0cBwMwcP+flyPXYiEhwrUb4umo2+PXBpfH1\n9+HQnV+IRFHwC5EoCn4hEkXBL0SiKPiFSJServa7OxqN8Ep7rGQRK2WWZZEafpH6Z7FV9iJZHQaA\npYWw723jK7mFSELNlfn5G7LVanzlu74SLv+VF/gqcKXYT23lSIWy2Zlz1LZwIbxyP9jiSsVQP19l\nnxgZpral2SvUVq2Gy5AN1Pg5n1nkSoCT6xeIqFIAWrHEHqIwWUSFYddp4TpqBerOL0SiKPiFSBQF\nvxCJouAXIlEU/EIkioJfiETpqdSXZ4ahgXCnEY+0OmqQ2mh5mUshrYgkk9e5DZEONdXBcFLKcmR/\npYj04lz9wa7tO7kfA5EuOvWwNleKJHz0Rc7ZIp1+RkZGqO3M+eng9uWF83TM2CiXASs1rjnu3MbH\n9VfDttlIvb2fvHqc2ubnuASbVXliEqvTBwANIgPG5GqW2ONK7BFCrIWCX4hEUfALkSgKfiESRcEv\nRKIo+IVIlA1JfWZ2AsAcgBaAprtPrjWGZR2tRKSXK6RW3OwVXk9t9/gYtTUibZAKkcysRSIfnrs8\nQ8eMDvNstEKk9l+5HG53BQCFSJusvBie38FKWGIFgIWIfLW0wG37JrgcOZCFMydPHHuWjrl1fJTa\nmvP8td51YD+1lavh1lvTr7xMxyxeuURtA5Fms/3DPFNwscGvubml8DXXjLSwY9mxsczC1dwMnf/X\n3f3CTdiPEKKH6GO/EImy0eB3AH9vZk+b2aGb4ZAQojds9GP/ve4+ZWbbATxmZi+6+xPXPqH7pnAI\nAGoDvPWxEKK3bOjO7+5T3f/PAfg2gHsCzzns7pPuPlmJ/PZZCNFbbjj4zazPzAauPgbwOwCev1mO\nCSE2l4187N8B4NvdzKMcwP9w97+NDTAz5KTw4MIil5TyQthNVpwRAArGJY9ixrOl+iL7vHg+LGpY\npDgmIsU9kfFxzViR0QKXAfuq4SKYWc7PuYlFaptf5sUsL0Zait16297g9p3vvIuOuW3vbmqr1fhX\nxrbzc/vp6dPB7dMz3PfxUS7PFiNSH2LFM43LdoVSeFzb+f5axfA5FyNt71Zzw8Hv7scBvOtGxwsh\nthZJfUIkioJfiERR8AuRKAp+IRJFwS9EovS0gKcBKJGqlXm7yccRJacvkvk2O8Mzs2olnk2X34AM\nWKnxjLlSxo8Vy7+qlbmkVCpyG1Ob6s0VOiaWjTY4zPvn+TzvkXf2fLiP3y3DvM/gUoPLm9v6uI+n\niAQLAC8Sqa8ek4Ir/JybkezTRoPPsbf58UpEBixGevVllfC1nxX49bsa3fmFSBQFvxCJouAXIlEU\n/EIkioJfiETp6Wo/2i1geS5oGqnxlXu2hF2qcvfL4KvDaPNV5cYSTzCqkIXUWAIGX68FPJKQUokk\nibTbvD1YgSR2lMsRH0t8Hj1Se67Qz1fuB4bCisTgCE/QeXX6dWq7uMJX0hebfCX97Gy4vmIr0h5u\nsMbPqxVpX5ZnkWvY+TxWcmJr8evU2TlHjrMa3fmFSBQFvxCJouAXIlEU/EIkioJfiERR8AuRKD2V\n+op5jt2j24K2hkdaVxXDbpbKXEhrDPBkm3YkgaQQkYAsD++zDu67RfZXr3PJrljislEz8p6dkRZg\nFqkXWInMY7vBpa2lFT6umYdfs2LfEB1TKPO2Z5dmuQQ7F8mQqgyHr7dqzpN3BiIJY2Xw+Wgu89cz\nJsAtrITPLTd+DbeIpGexOoKr0J1fiERR8AuRKAp+IRJFwS9Eoij4hUgUBb8QibKm1GdmDwP4PQDn\n3P0d3W0jAL4GYB+AEwA+5O5cp+nSdsc8kY6WW1wMYaJMIVL3rxSRa4y0DAPiUl+TFBNcasbqD/L9\ntSNvve1Ihb96ZK5yUpuuHfExklwIRGrW1SN16WYWwm2+CpHahNvHJqht+uQ0tS0s8Iy/pXJYLmss\n8/mIZXZuK/JzHh/kmaRzi7wl2guvHQ9ur9bG6JisGK4n2YxcG6tZz53/LwDct2rbgwAed/cDAB7v\n/i2EeAuxZvC7+xMAVpfCvR/AI93HjwB4/032Swixydzod/4d7n71c9gZdDr2CiHeQmx4wc/dHZES\n9GZ2yMyOmNmRxcj3HiFEb7nR4D9rZhMA0P0/3KEBgLsfdvdJd5+s1fjvqYUQveVGg/9RAA90Hz8A\n4Ds3xx0hRK9Yj9T3FQDvBTBmZqcBfArAZwB83cw+BuAkgA+t52DLjSZ+djbcRmulzfWmAmnxVSzy\nbLpWi2dflSJSX6XIJcL5xbB8VY9klWUkuw0AOt+YiB8VLol5bK7I27lHstFKkXkstLiPjXakuCd5\nzQYyfr95zzsPUFt97jK1HXn5Re7HtrBcVs3DUhkAWM6zPpci0qcN8mtncZ77f/JUuKXY3rdzqa9A\nQnf9Qt86gt/dP0JMv3kdxxFCvMnQL/yESBQFvxCJouAXIlEU/EIkioJfiETpaQFPRwErCMshLNsP\n4BlpxUgGU6HA5at6RA+xiNS31AoXaFyKyIp9EVkRhUhxzxZ/Xy5l/GXLSbHTRmOZHyvSj69UjBTp\nJBmEAFAk7r86xbPzJka4vFkyPseXZ6aobe5iWEbbM7aLjrnjnf+K2m7dMUptr504SW1TZ7jUd9vb\n3hXcPtPm1/ASkZ0bkUzL1ejOL0SiKPiFSBQFvxCJouAXIlEU/EIkioJfiETpqdQHMxQK4YKKxZzL\nTU2axcalshIp3AgAi0QmAQCLFHZskularvMssHL5xt5fW00ubWUlLr85ybQrRwpnFvNIkVHSEw4A\n8gKXlUp5+LzHx8O98wBg+vwCtV16LSzZAcC+PXdQ2+WFK8Ht1YgiNnv+LLU99txRajvx2hlqm1ng\n83jLLx4Mbq/3RbIEPSzdxgq/rkZ3fiESRcEvRKIo+IVIFAW/EImi4BciUXq62m8AMpIMUousOMPD\nbuY5T3xAxNQu8RXRQmRGqqXwinkk/wKFyHnFavgtzPOV7zzSAqzMVI42Vw/6WeE/ALVSZEIiSoCT\n4/VFbjeDtQFq23P3L1Hb6MgItVVK4RXzF489R8c88c//SG1PPf0stVUHedLPSpO/ZtXZ2eD24aFB\nOqZYCCs+sfZwq9GdX4hEUfALkSgKfiESRcEvRKIo+IVIFAW/EImynnZdDwP4PQDn3P0d3W2fBvAH\nAM53n/ZJd//uWvtyOJoWToIpRWS7XSNhCWWgxlsuzczS3qEAkX8AoFLm+2yR98qlSqQoYCTPIibL\nLEU0x4wkdQBAtRIe11/m8zvWx/2oRa6QZqQY4v79bw8fa5R3c7/9Dp6gMzQ0RG2xO9jc5XBiz0s/\nPUbH7BjdSW0H9s9R2/D27dyRSNu2c/NhH5srXO7NWG3I9ef1rOvO/xcA7gts/7y7H+z+WzPwhRBv\nLtYMfnd/AkC4u6YQ4i3LRr7zf9zMjprZw2bGk7SFEG9KbjT4vwjgdgAHAUwD+Cx7opkdMrMjZnak\nvsyLaAghessNBb+7n3X3lru3AXwJwD2R5x5290l3nyxFes4LIXrLDQW/mU1c8+cHADx/c9wRQvSK\n9Uh9XwHwXgBjZnYawKcAvNfMDqIjLJwA8IfrOVgbjkUP18jLnGed7ZkYC25//32/Rcf88Pvfo7aZ\n109R28rKCrVdmAlnX9XnwlINAJQisuLw8DC15YOR92UyhwCQlcJSarPOfaw1uY8jlT5q6x/i2XR3\nvf1AeMzAOB0zRCRdACj21aitvsS/TtbIuN//wAfpmF85/SvU9r3/w6+r5Ta/di5FrpHn/+mp4Pas\nn8ub5aFwTFwPawa/u38ksPmhDR9ZCLGl6Bd+QiSKgl+IRFHwC5EoCn4hEkXBL0Si9LiApyEj7bo8\nIl9NnQm3QapEimPuGeIS1fyJeWq7OHue2pYXw1lWzXme6eUZz6arDHGJrUQKNAJAq8ElpcZSPbg9\nL0QKO7a4rb/KJbY7iJwHAMPbiIyZ8UuuEMnsbDV5S7Q8MsdeDM9jbTuXHM/O8lSWhSbPZHzp5BS1\nzS3xTMxCMVyoc6nFz6tA7tvXkdSnO78QqaLgFyJRFPxCJIqCX4hEUfALkSgKfiESpadSX7sNLC+R\n7D3jEsrFubDEduKV43RMa2mR2sol/p5nXH1DoRyWxAYHeNFPtLn4snM7z4rri0hs8/P83KbOXwxu\nzzN+Yh5pbNiONCJcqfNzq5NefdVB0ksQgEWKXBYixU7bsZ6BZPuluXCGJgA8d/wlanvp7AVqm2ly\nebaZ8/Pee2BPcPuC8+t0vh6WxluR/o+r0Z1fiERR8AuRKAp+IRJFwS9Eoij4hUiUnq72OxwthFdm\nG+1I6yqSrHLhzDQdMxZ5Wxsf4/XPqsMD1Hb5SrgOW32et1WqVfiq/USkDlu1zBOTKsZr1jXr4Xl0\n8BqJgxFlYSji/yKpaQgASyPhOdm+cx8d402+Ur1SD18DALDS5La8GFYrTk69Tsc888Ir1HY5sqJ/\nJZKMVW/yxDWrh1+bZpsnMy0uhZPTWk3+Oq9Gd34hEkXBL0SiKPiFSBQFvxCJouAXIlEU/EIkynra\nde0F8JcAdqCTJ3HY3b9gZiMAvgZgHzotuz7k7jNr7a/ZIkkYkQSYOZLEsNzgskZ5qJ/70OBSWaHF\np2RlPjxufHQHHbNzYhe1tSOJG+2I9JkVuY8Dw+F6cMUiP9ZApKXYYD+fx0LOx126EE4w2jbOL5G5\nJV6b0CJ1+raN8gSpCmk3tveWfXRM3yBvk2U5r+9nkQSjWAnFOZK4ZpFbc6tFZMCbnNjTBPAn7n4n\ngHcD+GMzuxPAgwAed/cDAB7v/i2EeIuwZvC7+7S7/6j7eA7AMQC7AdwP4JHu0x4B8P7NclIIcfO5\nru/8ZrYPwF0AngSww92v/sTuDDpfC4QQbxHWHfxm1g/gmwA+4e5v+J2ruztI3QQzO2RmR8zsSHOZ\n1y4XQvSWdQW/mRXRCfwvu/u3upvPmtlE1z4B4FxorLsfdvdJd5/MK5GKN0KInrJm8JuZAXgIwDF3\n/9w1pkcBPNB9/ACA79x894QQm8V6svreA+CjAJ4zs2e62z4J4DMAvm5mHwNwEsCH1tpR2x3LRLYr\nFbiUYyQT8KWpcBsvANhW2kltKxFJqd3gX01WFsK27Tu30TG1Gs8SPHORy0aXr/CWYovL3P/+bWGp\nb3wnb081VK1SW9n56zI3z/04NXUquH020u7qygLPjpyc/GVqK9e4/yDXVdO59taKXIvI+P2yUuC2\nLOMSXDELv2aNSFu2diXs43TEv9WsGfzu/n0AbKZ+c91HEkK8qdAv/IRIFAW/EImi4BciURT8QiSK\ngl+IROltAU8HGkzpiagrBZLe9Mxx3q4ra3LZaGc/P21r8Yy/JQ9nEZ5Z4LKcz16mtp+9+iq1vfYa\nLzAZa5NV6gvLXiOjw3TMvt0883A0UtB06ux5aru0EC6q+fqPnwluB4A8knl417+ZpLZWZNzlK3PB\n7X/9vf9Nx7x4/AS1eUTOK0Qy6iIuoloJt/JqRdrKtdthyTyL+Lca3fmFSBQFvxCJouAXIlEU/EIk\nioJfiERR8AuRKD3u1Qc0SaHOLJJl1STvUVd4+zOcngn31QOAWpn3n+uPvB02iB9zrUgh0SUuHT7/\nwvPUdm6aZ/xNn+PndnlxMbi9RWRKALjnrndS2733contxOnT1Pb6xbDEduIsL+C5e99eantlmvdl\nbJd5kdF/+sFTwe3/96nwdgC4ssgzO1sZL1raDtezAcAzUwHAPXwh55EMvTYraGqRSqGr0J1fiERR\n8AuRKAp+IRJFwS9Eoij4hUiUnq72w4EWyexhK54AkFfDVX+tyFde0eL1zwb7+Lg88n746tFwItEv\n3H0XHTO681Zqm6vzFfjZSJnzxQafq0sL4fMukTkEgPNkDAA0SVcoANg5NEZtL7xwMmwo8VZYhW08\nwegbf/OP3I/h56jttVPhWoKLkRPznGeZFSKr9oXIan+rzce12uH5b7T4/hqkNVg70jJsNbrzC5Eo\nCn4hEkXBL0SiKPiFSBQFvxCJouAXIlHWlPrMbC+Av0SnBbcDOOzuXzCzTwP4AwBXC7l90t2/G9+b\nI2NSSaT+WYvIdnXjcth4pE3WWIkngjz2Yy4bvXgl7Ed2OVyvDgAuvcJr8V3Kw22aAGC+xvfZdi6X\nDY3sCW4fHh2lY0rb+Hy0M54EtXMX78o+t/JkcPvAHt42rFUoUtv0eZ4QNP36BWorEjnYsnDdPAAo\nWkTfpM2r4niby7osp60ZSRirE6nSI3G0mvXo/E0Af+LuPzKzAQBPm9ljXdvn3f3P1300IcSbhvX0\n6psGMN19PGdmxwDs3mzHhBCby3V95zezfQDuAnD1M93HzeyomT1sZrxVrRDiTce6g9/M+gF8E8An\n3P0KgC8CuB3AQXQ+GXyWjDtkZkfM7Eirzn9GKoToLesKfjMrohP4X3b3bwGAu59195a7twF8CcA9\nobHuftjdJ919MivxRRYhRG9ZM/jNzAA8BOCYu3/umu0T1zztAwB4TSohxJuO9az2vwfARwE8Z2ZX\ney19EsBHzOwgOvLfCQB/uNaOsoJhoBY+ZKsVkbYsLA/2lbjs8o79vB7czNlz1HbkxRPUlt9yR3D7\nM1NcamqdmKI29I1Q0/Awl9HGCjxDb7Eenqv+Pi7n1TIuKa0UeAbkxblwvUAA2Lt/f3B7fYhLsIVI\n5lusNl2T1bMD0G6Hx+UFvr/IZQWPZO5F5eqI1Ncg8rdF6i6WSP+v6yjht67V/u8jLG6uoekLId7M\n6Bd+QiSKgl+IRFHwC5EoCn4hEkXBL0Si9LSApxlQKYblkMU2z6RiMsme0YngdgDor/FstG//4AfU\nhhqXxAb6wjLVcjPSrqtS5cdq80KcRMkBAGQROadKMuNyIpcCQB6Rry7OX6a2VsTJXdvDWYQXG7GW\nVnwem1zNoy3gAMCJfFhoc98tItm1I3Jks8lfz3KBHy8nmYJ5TFUk10DhOrIOdecXIlEU/EIkioJf\niERR8AuRKAp+IRJFwS9EovRW6oNTyamYc4miZeQ9qslll5dP8Wy6F6d4Uc1dB3+Z2orEjzwieWXG\n5asCYj3hIgUfI1JUJQ+/pJVIFttQkdtqPIEQKHBpq78v7EcZvEhnXu2jtovz89RWr/NCrs1m+Nxa\nLT73Hpv7iKyYRaS5wT5+biuL4XNj2X4A4IXw/EYU0Z9Dd34hEkXBL0SiKPiFSBQFvxCJouAXIlEU\n/EIkSk+lvgIM5XZYjMgynv1mxbCbi3UuyZxb4cUlK/08c29kcJjaFkl1xIhShqJx/WfXOO+555GM\nv6kLC9TWXg4XQt3Wz+f34Nt4sdBakRdWPXmGy6n1PPza7Ir0BbRYccwVnvU5NMyLjC4sh8e1Wnx/\n1RLfX3+VZ4tai/tfLfFQa9TC9+DKEL8WX5+5EtweOczPoTu/EImi4BciURT8QiSKgl+IRFHwC5Eo\na64NmlkFwBMAyt3nf8PdP2Vm+wF8FcAogKcBfNTd+dIwgKIZJirhZp2W8fehOqmNNhJZ2oytsm/r\n4yvfY318pffScjiBpNmMtK0a553Lbx/nK9+tBu9oXI3UO7xwfjZ8rF185fiWMX7OeYOrDrORl7u1\nEF6NHt0+RseUIwlSu/vHqa0/otDMLYRfm4Lz8xqI9OvKWJIZgHaklmMxj4wrhBWwRqTu4lg1fO3/\nL5439XOs586/AuA33P1d6LTjvs/M3g3gTwF83t3fBmAGwMfWf1ghxFazZvB7h6s5h8XuPwfwGwC+\n0d3+CID3b4qHQohNYV3f+c0s63boPQfgMQCvALjs/v8+O50GsHtzXBRCbAbrCn53b7n7QQB7ANwD\n4BfWewAzO2RmR8zsyDL5ziyE6D3Xtdrv7pcB/AOAXwUwbGZXVx32AAj+1tPdD7v7pLtPViqxsjBC\niF6yZvCb2biZDXcfVwH8NoBj6LwJfLD7tAcAfGeznBRC3HzWkwYwAeARM8vQebP4urv/lZn9BMBX\nzew/A/gxgIfW2lFftYhfvXN70GYkaQYAGnWSnBFJfskzrnmMD3GJbTjj+9yxM9yuq69vhI8ZGqS2\ngZj8ExFNd9TCcwgAK7vD0uJQP5+PoQqXDiMu4h17d1Fbc3e4lVop0g5tgchyANBX4XJkNY/UEqwy\nyTeSjUXawwGAR2TWK0tz1JaVuf8ZkUwbDe7HEKklGKsjuJo1g9/djwK4K7D9ODrf/4UQb0H0Cz8h\nEkXBL0SiKPiFSBQFvxCJouAXIlEs1vrpph/M7DyAk90/xwBc6NnBOfLjjciPN/JW8+NWd+cpkNfQ\n0+B/w4HNjrj75JYcXH7ID/mhj/1CpIqCX4hE2crgP7yFx74W+fFG5Mcb+f/Wjy37zi+E2Fr0sV+I\nRNmS4Dez+8zsp2b2spk9uBU+dP04YWbPmdkzZnakh8d92MzOmdnz12wbMbPHzOyl7v+88ufm+vFp\nM5vqzskzZva+Hvix18z+wcx+YmYvmNm/627v6ZxE/OjpnJhZxcyeMrNnu378p+72/Wb2ZDduvmZm\nPFVwPbh7T/8ByNApA3YbgBKAZwHc2Ws/ur6cADC2Bcf9NQB3A3j+mm1/BuDB7uMHAfzpFvnxaQD/\nvsfzMQHg7u7jAQA/A3Bnr+ck4kdP5wSdfOP+7uMigCcBvBvA1wF8uLv9vwL4o40cZyvu/PcAeNnd\nj3un1PdXAdy/BX5sGe7+BIBLqzbfj04hVKBHBVGJHz3H3afd/Ufdx3PoFIvZjR7PScSPnuIdNr1o\n7lYE/24Ap675eyuLfzqAvzezp83s0Bb5cJUd7j7dfXwGAG+du/l83MyOdr8WbPrXj2sxs33o1I94\nEls4J6v8AHo8J70ompv6gt+97n43gN8F8Mdm9mtb7RDQeecHYv2qN5UvArgdnR4N0wA+26sDm1k/\ngG8C+IS7v6HrRy/nJOBHz+fEN1A0d71sRfBPAdh7zd+0+Odm4+5T3f/PAfg2trYy0VkzmwCA7v/n\ntsIJdz/bvfDaAL6EHs2JmRXRCbgvu/u3upt7PichP7ZqTrrHvu6iuetlK4L/hwAOdFcuSwA+DODR\nXjthZn1mNnD1MYDfAfB8fNSm8ig6hVCBLSyIejXYunwAPZgT6xRwfAjAMXf/3DWmns4J86PXc9Kz\norm9WsFctZr5PnRWUl8B8B+2yIfb0FEangXwQi/9APAVdD4+NtD57vYxdHoePg7gJQDfAzCyRX78\ndwDPATiKTvBN9MCPe9H5SH8UwDPdf+/r9ZxE/OjpnAD41+gUxT2KzhvNf7zmmn0KwMsA/ieA8kaO\no1/4CZEoqS/4CZEsCn4hEkXBL0SiKPiFSBQFvxCJouAXIlEU/EIkioJfiET5F++88jcZfzqfAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwcY8z_C2QLA",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"blue\"> Discussion and Analysis </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2W0ZtF82Xyb",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"blue\"> Fill here with your discussion </font>"
      ]
    }
  ]
}